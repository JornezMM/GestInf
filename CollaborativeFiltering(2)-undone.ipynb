{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://www.ubu.es/sites/default/files/portal_page/images/logo_color_2l_dcha.jpg\" height=\"150\" width=\"150\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Collaborative Filtering (2)\n",
    "[Nacho Santos](www.nacho.santos.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Other functions necessary for this assignment\n",
    "# The python file \"recommender_system.py\" must be in the same folder as this notebook, otherwise,\n",
    "# you have to add the path to the file\n",
    "from recommender_system import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# This line is necessary to show matplotlib plots inside the jupyter notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2 The cost funcion J and the gradient of J\n",
    "The objective of this point is to build a function to compute the cost J and the corresponding gradient of J. In particular, you are going to implement a function called **cofiCostFunc()** with the arguments(inputs) and outputs detailed below (the code of the function is partially predefined in a cell right after).\n",
    "\n",
    "**Arguments** (in this order)\n",
    "* *parameters* (the paramaters of the cost function, i.e. X and $\\theta$\n",
    "* *Y* (matrix of ratings)\n",
    "* *R* (matrix of watched movies)\n",
    "* *n_users* (number of users)\n",
    "* *n_movies* (number of movies)\n",
    "* *n_characteristics* (number of the filter characteristics)\n",
    "* *landa* (regularization parameter)\n",
    "\n",
    "**Outputs** (in this order)\n",
    "* *cost* (value of the cost function J)\n",
    "* *gradient* (gradient of the cost function J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Cost and gradient function\n",
    "def cofiCostFunc (parameters, Y, R, n_users, n_movies, n_features, lamb):\n",
    "# parameters: vector with the matrices X and Theta foldes\n",
    "# Y: matrix of ratings\n",
    "# R: matrix of watched movies\n",
    "# n_users: number of users (number of columns of the matrix Y)\n",
    "# n_movies: number of movies (number of rows of the matrix Y)\n",
    "# n_features: number of movies' features (a parameter of the CF algorithm)\n",
    "# lamb: regularization term\n",
    "#\n",
    "# cofiCostFunc rerturns the cost J and the gradient of J\n",
    "\n",
    "    # You need to return the following values correctly\n",
    "    cost=0\n",
    "    gradient=np.zeros_like(parameters)\n",
    "    \n",
    "    # Remember:\n",
    "    #  (1) To unfold X and Theta from parameters before computing J and the gradients\n",
    "    #  (2) To fold the gradient of J with respect to X and to Theta into a flattened vector gradient \n",
    "    #      that is returned by the function\n",
    "    \n",
    "    \n",
    "    # YOUR CODE ..................................\n",
    "    X = parameters[:n_movies*n_features].reshape(n_movies, n_features)\n",
    "    Theta = parameters[n_movies*n_features:].reshape(n_users, n_features)\n",
    "    cost=1/2*(np.sum(((np.dot(X, np.transpose(Theta))*R-Y)**2))+lamb*np.sum(Theta**2)+lamb*np.sum(X**2))\n",
    "    \n",
    "    Theta_gr=np.zeros((n_users, n_features))\n",
    "    X_gr=np.zeros((n_movies, n_features))\n",
    "\n",
    "    Theta_gr=np.dot(np.transpose(np.dot(X,np.transpose(Theta))*R-Y),X)+lamb*Theta\n",
    "    X_gr=np.dot((np.dot(X, np.transpose(Theta))*R-Y), Theta)+lamb*X\n",
    "\n",
    "    gradient=np.concatenate([X_gr.flatten(),Theta_gr.flatten()])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # YOUR CODE (end) ..................................\n",
    "    \n",
    "    return (cost, gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1 Input *parameters* of the cofiCostFunc\n",
    "\n",
    "**Features X and preferences Theta**\n",
    "\n",
    "The Collaborative Filtering (CF) algorithm is based on two sets of lineas regressions, the first one corresponds to the movies' features X, and the second one corresponds to the users' preferences Theta. Assuming n features, the matrix X will be:\n",
    "\n",
    "$$X=\\begin{bmatrix}x^{(1)}_{1} & ...& x^{(1)}_{n} \\\\. & ...& .\\\\x^{(m)}_{1} & ...& x^{(m)}_{n} \\end{bmatrix}$$\n",
    "\n",
    "where the i-th row of X corresponds to the feature vector $x^{(i)}$ for the i-th movie.\n",
    "\n",
    "And the matrix Theta will be:\n",
    "\n",
    "$$Theta=\\Theta=\\begin{bmatrix}\\theta^{(1)}_{1} & ...& \\theta^{(1)}_{n} \\\\. & ...& .\\\\\\theta^{(u)}_{1} & ...& \\theta^{(u)}_{n} \\end{bmatrix}$$\n",
    "\n",
    "where the j-th row of Theta corresponds to the preference vector $\\theta^{(j)}$ for the j-th user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Passing X and Theta to cofiCostFunc**\n",
    "\n",
    "We are going to use a optimize package scipy.optimize that requires using a **flattened vector** of parameters. However, in our problem tha parameters to be optimized are represented by two matrices, i.e. X and Theta. So, X and Theta must be passed to the cofiCostFunc as a **(mxn)+(u+n) vector**, called **parameters**:\n",
    "\n",
    "$${ \\left[ \\begin{matrix} { x }^{ (1) }, & ... & { x }^{ (m) }, \\end{matrix}\\begin{matrix} \\theta ^{ (1) }, & ... & \\theta ^{ (u) } \\end{matrix} \\right]  }_{ (m\\cdot n)+(u\\cdot n) }$$ \n",
    "\n",
    "However, inside the function, you can unfold the vector **parameters** and build the matrices X and Theta to compute J and the gradients according to the equations explained in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.2 Computing the cost J\n",
    "Suppose that the vector of features $x^{(i)}$ of the film i and the vector of preferences $\\theta^{(j)}$ of the user j are known, then the **estimate of the rating** of the user j for the movie i will be:\n",
    "\n",
    "$$\\widehat{y}^{(i,j)}=x^{(i)}(\\theta^{(j)})^{T}$$\n",
    "\n",
    "The error of the estimate will be the difference between the estimate of rating $\\widehat{y}^{(i,j)}$ and the real ratings $y^{(i,j)}$\n",
    "\n",
    "The **cost J** is defined as the the average of the squares of the errors plus two regularization terms:\n",
    "\n",
    "$$J=\\frac { 1 }{ 2 } \\sum _{ (i,j):r(i,j)=1 }^{  }{ \\left( { x }^{ (i) }({ \\theta  }^{ (j) })^{ T }-{ y }^{ (i,j) } \\right) ^{ 2 } } +\\quad \\frac { \\lambda  }{ 2 } \\sum _{ i=1 }^{ m }{ \\sum _{ k=1 }^{ n }{ ({ x }_{ k }^{ (i) })^{ 2 } }  } +\\frac { \\lambda  }{ 2 } \\sum _{ j=1 }^{ u }{ \\sum _{ k=1 }^{ n }{ ({ \\theta  }_{ k }^{ (j) })^{ 2 } }  } $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Task 7\n",
    "***\n",
    "Implement the cost J as a vectorized expression (recommended). For example, the estimate of ratings can be expressed as:\n",
    "\n",
    "$$\\widehat{Y}=X\\Theta^{T}$$\n",
    "\n",
    "Now, go back and **complete the cofiCostFunc code to compute the cost J**. Remeber that J is scalar value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3 Checking the cost J\n",
    "Now, you will import a data set and check the cofiCostFunc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset for checking\n",
    "Y=np.load('YmatrixTest.npy')\n",
    "R=np.load('RmatrixTest.npy')\n",
    "X=np.load('XmatrixTest.npy')\n",
    "Theta=np.load('ThetamatrixTest.npy')\n",
    "\n",
    "# dimension\n",
    "n_users = Y.shape[1]\n",
    "n_movies = Y.shape[0]\n",
    "n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8\n",
    "***\n",
    "Call cofiCostFunc with lamb=0 (without regularization term) and check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of J (without regularization term) is 22.22 (it should be 22.22)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Cost J (without regularization term)\n",
    "J=0\n",
    "parameters=np.concatenate([X.flatten(),Theta.flatten()])\n",
    "\n",
    "# YOUR CODE ..................................\n",
    "# call cofiCostFunc with lamb=0 (without regularization term)\n",
    "J=cofiCostFunc(parameters, Y, R, n_users, n_movies, n_features, 0)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# YOUR CODE (end)..................................\n",
    "\n",
    "print('The value of J (without regularization term) is %0.2f (it should be 22.22)' % J )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9\n",
    "***\n",
    "Call cofiCostFunc with lamb=1.5 (with regularization term) and check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of J (with regularization term equal to 1.5) is 31.34 (it should be 31.34)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Cost J (with regularization term)\n",
    "J=0\n",
    "parameters=[]\n",
    "\n",
    "# YOUR CODE ..................................\n",
    "# call cofiCostFunc with lamb=1.5 (without regularization term)\n",
    "parameters=np.concatenate([X.flatten(),Theta.flatten()])\n",
    "J=cofiCostFunc(parameters, Y, R, n_users, n_movies, n_features, 1.5)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# YOUR CODE (end)..................................\n",
    "\n",
    "print('The value of J (with regularization term equal to 1.5) is %0.2f (it should be 31.34)' % J )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.4 Computing the gradient of J\n",
    "The **gradient of J** depends on the two types of parameters, i.e. X and Theta. The corresponding equations are:\n",
    "\n",
    "$$\\frac { \\partial J }{ \\partial { \\theta  }_{ k }^{ (j) } } =\\sum _{ i:r(i,j)=1 }^{  }{ \\left( { x }^{ (i) }({ \\theta  }^{ (j) })^{ T }-{ y }^{ (i,j) } \\right) { x }_{ k }^{ (i) } } +\\lambda { \\theta  }_{ k }^{ (j) }$$\n",
    "\n",
    "$$\\frac { \\partial J }{ \\partial { x }_{ k }^{ (i) } } =\\sum _{ j:r(i,j)=1 }^{  }{ \\left( { x }^{ (i) }({ \\theta  }^{ (j) })^{ T }-{ y }^{ (i,j) } \\right) \\theta _{ k }^{ (j) } } +\\lambda { x }_{ k }^{ (i) }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Task 10\n",
    "***\n",
    "Now, go back and **complete the cofiCostFunc code to compute the gradient of J**. Remember to use vectorized operations instead of using for loops.\n",
    "\n",
    "Note that the outputs of cofiCostFunc are the cost J (scalar value) and the gradient, again a **flattened vector of the corresponding gradients of X and Theta**:\n",
    "\n",
    "$${ \\left[ \\begin{matrix} \\frac { \\partial J }{ \\partial { x }^{ (1) } } , & ... & \\frac { \\partial J }{ \\partial { x }^{ (m) } } , & \\frac { \\partial J }{ \\partial \\theta ^{ (1) } } , & ... & \\frac { \\partial J }{ \\partial \\theta ^{ (u) } }  \\end{matrix} \\right]  }_{ (m\\cdot n)+(u\\cdot n) }$$\n",
    "\n",
    "After computing both gradients, you should reshape them into a flattened vector called **gradient** that will be returned by the cofiCostFunc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Checking the gradient of J\n",
    "For the same dataset of the last poit, you will check the gradient of J computed by your cofiCostFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The above two columns you get should be very similar.\n",
      "(Left - Your Numerical Gradient, Right - Analytical Gradient)\n",
      "\n",
      "(0.6510065716669455, 0.6510065716673111)\n",
      "(0.8086199481496803, 0.8086199481496615)\n",
      "(0.1748463082038021, 0.17484630820398653)\n",
      "(-0.02083443377765004, -0.020834433777354423)\n",
      "(-0.0969136727230202, -0.09691367272315933)\n",
      "(-0.05519967229195011, -0.05519967229209706)\n",
      "(-0.142760283869392, -0.14276028386938608)\n",
      "(-0.17732357608102323, -0.17732357608102228)\n",
      "(-0.03834232967708795, -0.0383423296769289)\n",
      "(0.03836026308018381, 0.03836026308007702)\n",
      "(0.13816100211144766, 0.13816100211155571)\n",
      "(-0.12240560103710107, -0.12240560103713898)\n",
      "(0.7411323881362231, 0.7411323881372027)\n",
      "(0.5063526181378619, 0.5063526181385095)\n",
      "(0.6019881590632603, 0.6019881590637675)\n",
      "(-0.034381790864623785, -0.03438179086482943)\n",
      "(-0.03184351007767816, -0.03184351007746739)\n",
      "(-0.02758451165874032, -0.027584511658768275)\n",
      "(-0.042736615147864754, -0.042736615147863505)\n",
      "(-0.03958152850397356, -0.03958152850408796)\n",
      "(-0.034287587387105134, -0.034287587387091215)\n",
      "(0.009093344770783052, 0.00909334477085052)\n",
      "(0.008422016671283394, 0.00842201667117553)\n",
      "(0.007295590733757962, 0.007295590733911297)\n",
      "(-0.0691455646384398, -0.06914556463849317)\n",
      "(-0.20286137449365693, -0.2028613744936064)\n",
      "(-0.008107482219743556, -0.008107482219513153)\n",
      "If your backpropagation implementation is correct, then \n",
      "the relative difference will be small (less than 1e-9).\n",
      "Relative Difference: 4.73573827e-13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check gradients (without regularization term) by running the next function\n",
    "checkCostFunction(cofiCostFunc,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The above two columns you get should be very similar.\n",
      "(Left - Your Numerical Gradient, Right - Analytical Gradient)\n",
      "\n",
      "(-0.8438778121666601, -0.8438778121611398)\n",
      "(-0.4938559369138673, -0.4938559369085195)\n",
      "(0.19806508614550467, 0.19806508614383111)\n",
      "(1.4376776945423941, 1.4376776945371665)\n",
      "(0.2985279134515295, 0.29852791345101465)\n",
      "(0.8378962250832345, 0.837896225079484)\n",
      "(1.5759434813045203, 1.5759434813026372)\n",
      "(1.647944208378327, 1.6479442083797882)\n",
      "(1.7928284798252037, 1.7928284798243164)\n",
      "(0.9970991699148612, 0.9970991699117586)\n",
      "(0.4381528012986635, 0.4381528012980987)\n",
      "(0.48982028583388626, 0.48982028583605)\n",
      "(1.3602860015016205, 1.3602860015027831)\n",
      "(1.207720825884273, 1.207720825884889)\n",
      "(0.8066626286451495, 0.8066626286398169)\n",
      "(0.7645504397135738, 0.7645504397112362)\n",
      "(1.5899860724033488, 1.5899860724011465)\n",
      "(1.249985418216859, 1.249985418214183)\n",
      "(0.727836136102944, 0.7278361361022266)\n",
      "(0.5309091039107372, 0.5309091039126718)\n",
      "(-0.11300006953263164, -0.11300006953249297)\n",
      "(0.6697664570332051, 0.6697664570312007)\n",
      "(0.14958034421752586, 0.14958034421463878)\n",
      "(0.2326250612272318, 0.23262506122391596)\n",
      "(1.3399031939176353, 1.339903193918429)\n",
      "(1.2064501920239223, 1.2064501920263435)\n",
      "(1.1099786350809993, 1.1099786350831007)\n",
      "If your backpropagation implementation is correct, then \n",
      "the relative difference will be small (less than 1e-9).\n",
      "Relative Difference: 1.36802220e-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check gradients (with regularization term) by running the next function\n",
    "checkCostFunction(cofiCostFunc,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3 Learning and recommendation\n",
    "Finally, you will use your cofiCostFun to make predictions using the initial Movielens dataset. Part of the python code you need is already written in the next cells. You only have to complete those lines that are explicitly required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11\n",
    "***\n",
    "Load the matrix Y and R computed in the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Task: load matrix Y and R\n",
    "# YOUR CODE ..................................\n",
    "Y=np.load(\"Y.npy\")\n",
    "R=np.load(\"R.npy\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12\n",
    "***\n",
    "* Get the number of users and movies and assign the corresponding variables n_users, n_movies.\n",
    "* Set the initial parameters (Theta, X) with random values.\n",
    "* Fold X and Theta into the variable initial_parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the number of features\n",
    "n_features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE ..................................\n",
    "n_movies=Y.shape[0]\n",
    "n_users=Y.shape[1]\n",
    "X = np.random.rand(n_movies,n_features)\n",
    "Theta= np.random.rand(n_users,n_features)\n",
    "initial_parameters=np.zeros_like(parameters)\n",
    "initial_parameters=np.concatenate([X.flatten(),Theta.flatten()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we set the rest of the parameters and minimize the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the regularization parameter\n",
    "lamb = 10\n",
    "\n",
    "# Define a function to be minimized\n",
    "def cofiCostFunc_minimize(parameters):\n",
    "    return cofiCostFunc(parameters,Y, R, n_users, n_movies, n_features,lamb)\n",
    "\n",
    "# Set the number of iteations\n",
    "max_iter=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: 66581.227178\n",
      "         Iterations: 200\n",
      "         Function evaluations: 305\n",
      "         Gradient evaluations: 305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jorge\\OneDrive\\Documentos\\4ยบ Curos\\gi\\ml-100k\\venv\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:703: OptimizeWarning: Maximum number of iterations has been exceeded.\n",
      "  res = _minimize_cg(fun, x0, args, jac, callback, **options)\n"
     ]
    }
   ],
   "source": [
    "# Minimize the function using minimize from the package scipy.optimize and get the optimized parameters\n",
    "parameters = (minimize(cofiCostFunc_minimize,initial_parameters,method=\"CG\",jac=True,\n",
    "                   options={'maxiter':max_iter, \"disp\":True})).x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 13\n",
    "***\n",
    "Get the matrix of predictions P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE ..................................\n",
    "X = parameters[:n_movies*n_features].reshape(n_movies, n_features)\n",
    "Theta = parameters[n_movies*n_features:].reshape(n_users, n_features)\n",
    "P=np.zeros((n_movies,n_users))\n",
    "P=np.dot(X,np.transpose(Theta))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 14\n",
    "***\n",
    "Show the titles of the top-5 predictions for the first user u=0, for those films user u did not watch: r(i,u)=0 (they will be the top-5 recommendations)\n",
    "\n",
    "#### Tips\n",
    "* You can import movies' titles using Pandas (see the first notebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.5071559  3.88225438 2.91447481 ... 4.28054535 4.45649066 3.39094925]\n",
      " [2.99855559 2.65958974 1.89421228 ... 2.68327533 3.64366172 3.86049875]\n",
      " [3.56991802 2.28718326 2.05855209 ... 2.48468672 3.14679429 2.74344322]\n",
      " ...\n",
      " [0.4343731  0.32051774 0.28044773 ... 0.37123644 0.35461338 0.41778969]\n",
      " [0.46900636 0.4845817  0.26239095 ... 0.42878835 0.63049566 0.54955072]\n",
      " [0.8905475  0.62655483 0.44370646 ... 0.58564829 0.68099479 0.66258465]]\n",
      "Belle de jour (1967)\n",
      "3.556772149762193\n",
      "Sneakers (1992)\n",
      "3.7653958019628586\n",
      "Get Shorty (1995)\n",
      "3.671290590030943\n",
      "Mr. Smith Goes to Washington (1939)\n",
      "3.7055028865986914\n",
      "Mighty Aphrodite (1995)\n",
      "4.416987019388705\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE ..................................\n",
    "from pandas import read_table\n",
    "# read csv file\n",
    "items = read_table('u.item',header=None,sep='|',encoding='ISO-8859-1')\n",
    "# remove collumns 2-24\n",
    "items.drop(range(2,24),axis=1, inplace=True)\n",
    "print(P)\n",
    "\n",
    "top5= np.argsort(P[R[:,0]==0,0])[::-1][:5]\n",
    "\n",
    "for i in top5:\n",
    "    \n",
    "    print(items[1][i])\n",
    "    print(P[i][0])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.11.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbb56b52f2350d021fb0428e80f310eef5f59ac0bb0439ce70725af5937a5e70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
